{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1f40EeRuvAkO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frames [299, 299, 299, 299]\n",
            "Total number of videos:  4\n",
            "Average frame per video: 299.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "\n",
        "video_files = glob.glob('C:\\\\Users\\\\princ\\\\OneDrive\\\\Desktop\\\\Agnethon\\\\tp\\\\*.mp4')\n",
        "\n",
        "\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames\" , frame_count)\n",
        "print(\"Total number of videos: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\princ\\AppData\\Local\\Temp\\ipykernel_10128\\1826104834.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U92Ovn3JvV52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of videos already present:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\princ\\AppData\\Local\\Temp\\ipykernel_18264\\3509773998.py:56: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d69c42c3f6f4700b330dab5fb031687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import face_recognition\n",
        "import glob\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "def frame_extract(path):\n",
        "    vidObj = cv2.VideoCapture(path) \n",
        "    success = True\n",
        "    while success:\n",
        "        success, image = vidObj.read()\n",
        "        yield image\n",
        "\n",
        "def create_face_videos(path_list, out_dir):\n",
        "    \n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "    \n",
        "    already_present_count = glob.glob(os.path.join(out_dir, '*.mp4'))\n",
        "    print(\"Number of videos already present: \", len(already_present_count))\n",
        "    \n",
        "    for path in tqdm(path_list):\n",
        "        out_path = os.path.join(out_dir, os.path.basename(os.path.normpath(path)))\n",
        "\n",
        "        \n",
        "        if os.path.exists(out_path):\n",
        "            print(\"File already exists: \", out_path)\n",
        "            continue\n",
        "\n",
        "        frames = []\n",
        "        out = None\n",
        "        try:\n",
        "            out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (112, 112))\n",
        "            for idx, frame in enumerate(frame_extract(path)):\n",
        "                if idx <= 5:  # Process only the first 6 frames for testing\n",
        "                    frames.append(frame)\n",
        "                    if len(frames) == 4:\n",
        "                        faces = face_recognition.batch_face_locations(frames)\n",
        "                        for i, face in enumerate(faces):\n",
        "                            if face:\n",
        "                                top, right, bottom, left = face[0]\n",
        "                                try:\n",
        "                                    out.write(cv2.resize(frames[i][top:bottom, left:right, :], (112, 112)))\n",
        "                                except Exception as e:\n",
        "                                    print(\"Error:\", e)\n",
        "                        frames = []\n",
        "                else:\n",
        "                    break  \n",
        "        except Exception as e:\n",
        "            print(\"Error processing video:\", path, \"-\", e)\n",
        "        finally:\n",
        "            if out:\n",
        "                out.release()\n",
        "\n",
        "\n",
        "video_files = glob.glob('C:\\\\Users\\\\princ\\\\OneDrive\\\\Desktop\\\\Agnethon\\\\tp\\\\*.mp4')  # Adjust the path to your video files\n",
        "output_directory = \"C:\\\\Users\\\\princ\\\\OneDrive\\\\Desktop\\\\Agnethon\\\\onlyfacevideos\\\\\"  # Adjust the path to your output directory\n",
        "\n",
        "create_face_videos(video_files, output_directory)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
